{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "2 Pytorch_BERT+CRF_NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5851b94fda8a423b8e7d7a58a04f0c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01d20dea2eea445b9696294ecc627773",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb303f64b0ed4b3c988b4aac57d815c2",
              "IPY_MODEL_deb6bf633119403f8d805716cafb0ed8"
            ]
          }
        },
        "01d20dea2eea445b9696294ecc627773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb303f64b0ed4b3c988b4aac57d815c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9d27265d57e4687827bdc736a423b2d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd6e820871ea450dac28bed1117f3f57"
          }
        },
        "deb6bf633119403f8d805716cafb0ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9924ba9f0e1b49ba93dcf14e64ed9766",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 1.52kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9c17a322acf441a8d2181e1e1d7ed43"
          }
        },
        "e9d27265d57e4687827bdc736a423b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd6e820871ea450dac28bed1117f3f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9924ba9f0e1b49ba93dcf14e64ed9766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9c17a322acf441a8d2181e1e1d7ed43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "262c7059122a4eb2bb7294f884f5d119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd6c7ce2235b48ceb696c27301270942",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb16bea2fab3457ab8e466cad4c2a7ed",
              "IPY_MODEL_7b6dd970c5554b19b2ece5a973614000"
            ]
          }
        },
        "cd6c7ce2235b48ceb696c27301270942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb16bea2fab3457ab8e466cad4c2a7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31076581e61446b6b6b841d50daeb513",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6fbcfc329a54a189cd1ff70e0140b64"
          }
        },
        "7b6dd970c5554b19b2ece5a973614000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_048ad2a900e94297a011cc623bac13ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:05&lt;00:00, 71.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80e99e1f1d0e40ee9d333bebb5248d0b"
          }
        },
        "31076581e61446b6b6b841d50daeb513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6fbcfc329a54a189cd1ff70e0140b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "048ad2a900e94297a011cc623bac13ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80e99e1f1d0e40ee9d333bebb5248d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh3ZjelBtlf4",
        "outputId": "0b9d653e-7b3f-45f8-e477-ecdbe26fbca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import argparse\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTiMnqLttyea",
        "outputId": "96a1cd09-a36f-40f8-b0d6-384e0b4f7383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "print(os.listdir('.'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'gdrive', '.ipynb_checkpoints', 'SequenceTagger.py', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrmf3EMtlf8"
      },
      "source": [
        "# Hyper Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p82_NnqQtlf8"
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--dataset', default='msra')\n",
        "parser.add_argument('--seed', default=1234)\n",
        "parser.add_argument('--store_dir', default=None)\n",
        "\n",
        "parser.add_argument('--max_epoch_num', default=5)\n",
        "parser.add_argument('--min_epoch_num', default=5)\n",
        "parser.add_argument('--batch_size', default=32)\n",
        "parser.add_argument('--max_len', default=128)\n",
        "parser.add_argument('--patience', default=0.02)\n",
        "parser.add_argument('--patience_num', default=5)\n",
        "\n",
        "parser.add_argument('--full_finetuning', default=True)\n",
        "parser.add_argument('--learning_ratio', default=3e-5)\n",
        "parser.add_argument('--weight_decay', default=0.01)\n",
        "parser.add_argument('--clip_grad', default=5)\n",
        "\n",
        "parser.add_argument('--device', default=None)\n",
        "\n",
        "args = parser.parse_args([])\n",
        "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_params_dir = '/content/gdrive/My Drive/BERT-NER-Chinese/experiments/' + args.dataset\n",
        "json_path = os.path.join(model_params_dir, 'params.json')\n",
        "assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
        "# params = utils.Params(json_path)\n",
        "\n",
        "data_dir = '/content/gdrive/My Drive/BERT-NER-Chinese/data/' + args.dataset\n",
        "if args.dataset == 'msra':\n",
        "    bert_class = 'bert-base-chinese'\n",
        "else:\n",
        "    bert_class = 'bert-base-cased'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uKSHNN5tlf_",
        "outputId": "8be3cf05-ade9-4da1-cf5e-6834fd3a3c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# set seed for random parts\n",
        "random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "# params.seed = args.seed"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc67952b570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka7zXe81tlgC"
      },
      "source": [
        "# Define dataloader for following step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ7s_oOrtlgD",
        "outputId": "08eacad1-be38-4fff-de29-050c13069927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "! pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "class DataLoader(object):\n",
        "    def __init__(self, data_dir, bert_class, args, token_pad_idx=0, tag_pad_idx=1):\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = args.batch_size\n",
        "        self.max_len = args.max_len\n",
        "        self.device = args.device\n",
        "        self.seed = args.seed\n",
        "        self.token_pad_idx = token_pad_idx\n",
        "        self.tag_pad_idx = tag_pad_idx\n",
        "        \n",
        "        tags = self.load_tags()\n",
        "        self.tag2idx = {tag: idx for idx, tag in enumerate(tags)}\n",
        "        self.idx2tag = {idx: tag for idx, tag in enumerate(tags)}\n",
        "        \n",
        "        args.tag2idx = self.tag2idx\n",
        "        args.idx2tag = self.idx2tag\n",
        "        \n",
        "        self.tokenizer = BertTokenizer.from_pretrained(bert_class, do_lower_case=False)\n",
        "        \n",
        "    def load_tags(self):\n",
        "        tags  = []\n",
        "        tags_path = os.path.join(self.data_dir, 'tags.txt')\n",
        "        \n",
        "        with open(tags_path, 'r') as file:\n",
        "            for tag in file:\n",
        "                tags.append(tag.strip())\n",
        "        return tags\n",
        "    \n",
        "    def load_sentence_tags(self, sentence_path, tags_path, data={}):\n",
        "        sentences = []\n",
        "        tags = []\n",
        "        \n",
        "        with open(sentence_path, 'r') as file:\n",
        "            for line in file:\n",
        "                tokens = line.strip().split(' ')\n",
        "                subwords = list(map(self.tokenizer.tokenize, tokens))\n",
        "                subword_lengths = list(map(len, subwords))\n",
        "                subwords = ['[CLS]'] + [item for indices in subwords for item in indices]\n",
        "                # indice words except [CLS]\n",
        "                token_start_idxs = list(range(1,len(subwords)))\n",
        "                \n",
        "                bert_tokens = self.tokenizer.convert_tokens_to_ids(subwords)\n",
        "                sentences.append((bert_tokens, token_start_idxs))\n",
        "                # len(bert_tokens) - len(token_start_idxs) = 1\n",
        "  \n",
        "                \n",
        "        if tags_path != None:\n",
        "            with open(tags_path, 'r') as file:\n",
        "                for line in file:\n",
        "                    tag_seq = [self.tag2idx.get(tag) for tag in line.strip().split(' ')]\n",
        "                    tags.append(tag_seq)\n",
        "            \n",
        "            # Check the corresponding between sentences and tags\n",
        "            assert len(sentences) == len(tags)\n",
        "            for i in range(len(tags)):\n",
        "                assert len(tags[i]) == len(sentences[i][0])-1\n",
        "        \n",
        "        data['sentences'] = sentences\n",
        "        data['tags'] = tags\n",
        "        data['size'] = len(sentences)\n",
        "        \n",
        "    def load_data(self, data_class):\n",
        "        data = {}\n",
        "        \n",
        "        if data_class in ['train', 'val', 'test']:\n",
        "            sentence_path = os.path.join(data_dir, data_class, 'sentences.txt')\n",
        "            tags_path = os.path.join(data_dir, data_class, 'tags.txt')\n",
        "            \n",
        "            self.load_sentence_tags(sentence_path, tags_path, data)\n",
        "        \n",
        "        elif data_class == 'interactive':\n",
        "            sentence_path = os.path.join(sentence_path, data_class, 'sentences.txt')\n",
        "            tags_path=None\n",
        "            self.load_sentence_tags(sentence_path, tags_path, data)\n",
        "            \n",
        "        else:\n",
        "            raise ValueError(\"No data in train/val/test or interactve!\")\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def data_iterator(self, data, shuffle=False):\n",
        "        order = list(range(data['size']))\n",
        "        if shuffle:\n",
        "            random.seed(self.seed)\n",
        "            random.shuffle(order)\n",
        "        InterModel = False if 'tags' in data else True\n",
        "        \n",
        "        if data['size'] % self.batch_size == 0:\n",
        "            BATCH_SIZE = data['size'] // self.batch_size\n",
        "        else:\n",
        "            BATCH_SIZE = data['size'] // self.batch_size + 1\n",
        "        \n",
        "        for i in range(BATCH_SIZE):\n",
        "            # fetch sentences and tags\n",
        "            if i * self.batch_size < data['size'] < (i+1) * self.batch_size:\n",
        "                sentences = [data['sentences'][idx] for idx in order[i*self.batch_size:]]\n",
        "                if not InterModel:\n",
        "                    tags = [data['tags'][idx] for idx in order[i*self.batch_size:]]\n",
        "            else:\n",
        "                sentences = [data['sentences'][idx] for idx in order[i*self.batch_size:(i+1)*self.batch_size]]\n",
        "                if not InterModel:\n",
        "                    tags = [data['tags'][idx] for idx in order[i*self.batch_size:(i+1)*self.batch_size]]\n",
        "\n",
        "            # batch length\n",
        "            batch_len = len(sentences)\n",
        "\n",
        "            # compute length of longest sentence in batch\n",
        "            batch_max_subwords_len = max([len(s[0]) for s in sentences])\n",
        "            max_subwords_len = min(batch_max_subwords_len, self.max_len)\n",
        "            max_token_len = 0\n",
        "\n",
        "\n",
        "            # prepare a numpy array with the data, initialising the data with pad_idx\n",
        "            batch_data = self.token_pad_idx * np.ones((batch_len, max_subwords_len))\n",
        "            batch_token_starts = []\n",
        "            \n",
        "            # copy the data to the numpy array\n",
        "            for j in range(batch_len):\n",
        "                cur_subwords_len = len(sentences[j][0])\n",
        "                if cur_subwords_len <= max_subwords_len:\n",
        "                    batch_data[j][:cur_subwords_len] = sentences[j][0]\n",
        "                else:\n",
        "                    batch_data[j] = sentences[j][0][:max_subwords_len]\n",
        "                token_start_idx = sentences[j][-1]\n",
        "                token_starts = np.zeros(max_subwords_len)\n",
        "                token_starts[[idx for idx in token_start_idx if idx < max_subwords_len]] = 1\n",
        "                batch_token_starts.append(token_starts)\n",
        "                max_token_len = max(int(sum(token_starts)), max_token_len)\n",
        "            \n",
        "            if not InterModel:\n",
        "                batch_tags = self.tag_pad_idx * np.ones((batch_len, max_token_len))\n",
        "                for j in range(batch_len):\n",
        "                    cur_tags_len = len(tags[j])  \n",
        "                    if cur_tags_len <= max_token_len:\n",
        "                        batch_tags[j][:cur_tags_len] = tags[j]\n",
        "                    else:\n",
        "                        batch_tags[j] = tags[j][:max_token_len]\n",
        "            \n",
        "            # since all data are indices, we convert them to torch LongTensors\n",
        "            batch_data = torch.tensor(batch_data, dtype=torch.long)\n",
        "            batch_token_starts = torch.tensor(batch_token_starts, dtype=torch.long)\n",
        "            if not InterModel:\n",
        "                batch_tags = torch.tensor(batch_tags, dtype=torch.long)\n",
        "\n",
        "            # shift tensors to GPU if available\n",
        "            batch_data, batch_token_starts = batch_data.to(self.device), batch_token_starts.to(self.device)\n",
        "            if not InterModel:\n",
        "                batch_tags = batch_tags.to(self.device)\n",
        "                yield batch_data, batch_token_starts, batch_tags\n",
        "            else:\n",
        "                yield batch_data, batch_token_starts\n",
        "\n",
        "                \n",
        "data_loader = DataLoader(data_dir, bert_class, args, token_pad_idx=0, tag_pad_idx=-1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_iRkGnltlgG",
        "outputId": "ecb55121-0085-4d24-b790-29b47a9c6249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "load_proc_start = time.time()\n",
        "\n",
        "train = data_loader.load_data('train')\n",
        "val = data_loader.load_data('val')\n",
        "test = data_loader.load_data('test')\n",
        "load_proc_time = time.time() - load_proc_start\n",
        "lp_mins, lp_secs = load_proc_time/60, load_proc_time%60\n",
        "print('Load and Processing data cost: {0}m {1:2f}s.'.format(int(lp_mins), lp_secs))\n",
        "\n",
        "args.train_size = train['size']\n",
        "args.val_size = val['size']\n",
        "args.test_size = test['size']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load and Processing data cost: 1m 14.813748s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUKZPBn9tlgI"
      },
      "source": [
        "# Model Structure and optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5OVuYM-tlgJ",
        "outputId": "9299489e-4f20-4bdd-fd4f-a214e3d77062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5851b94fda8a423b8e7d7a58a04f0c98",
            "01d20dea2eea445b9696294ecc627773",
            "eb303f64b0ed4b3c988b4aac57d815c2",
            "deb6bf633119403f8d805716cafb0ed8",
            "e9d27265d57e4687827bdc736a423b2d",
            "cd6e820871ea450dac28bed1117f3f57",
            "9924ba9f0e1b49ba93dcf14e64ed9766",
            "b9c17a322acf441a8d2181e1e1d7ed43",
            "262c7059122a4eb2bb7294f884f5d119",
            "cd6c7ce2235b48ceb696c27301270942",
            "fb16bea2fab3457ab8e466cad4c2a7ed",
            "7b6dd970c5554b19b2ece5a973614000",
            "31076581e61446b6b6b841d50daeb513",
            "c6fbcfc329a54a189cd1ff70e0140b64",
            "048ad2a900e94297a011cc623bac13ea",
            "80e99e1f1d0e40ee9d333bebb5248d0b"
          ]
        }
      },
      "source": [
        "! pip install pytorch-crf\n",
        "\n",
        "from SequenceTagger import BertForSequenceTagging, Bert_CRF\n",
        "from transformers.optimization import get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "model = Bert_CRF.from_pretrained(bert_class, num_labels=len(args.tag2idx))\n",
        "model.to(args.device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.6/dist-packages (0.7.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5851b94fda8a423b8e7d7a58a04f0c98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "262c7059122a4eb2bb7294f884f5d119",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411577189.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing Bert_CRF: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing Bert_CRF from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing Bert_CRF from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Bert_CRF were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias', 'crf.start_transitions', 'crf.end_transitions', 'crf.transitions']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bert_CRF(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              "  (crf): CRF(num_tags=7)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKouNU2MtlgL"
      },
      "source": [
        "# finetuing whole model or only classifier\n",
        "if args.full_finetuning:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
        "         'weight_decay': args.weight_decay},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
        "         'weight_decay': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr=args.learning_ratio,\n",
        "                  correct_bias=False)\n",
        "train_steps = args.train_size // args.batch_size\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=train_steps, num_training_steps=args.max_epoch_num * train_steps)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSmg3sEatlgO"
      },
      "source": [
        "# Train Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EDNVgETtlgO"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_entities(seq, suffix=False):\n",
        "    if any(isinstance(s, list) for s in seq):\n",
        "        seq = [item for sublist in seq for item in sublist + ['O']]\n",
        "    prev_tag = 'O'\n",
        "    prev_type = ''\n",
        "    begin_offset = 0\n",
        "    chunks = []\n",
        "    for i, chunk in enumerate(seq + ['O']):\n",
        "        if suffix:\n",
        "            tag = chunk[-1]\n",
        "            type_ = chunk.split('-')[0]\n",
        "        else:\n",
        "            tag = chunk[0]\n",
        "            type_ = chunk.split('-')[-1]\n",
        "\n",
        "        if end_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "            chunks.append((prev_type, begin_offset, i-1))\n",
        "        if start_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "            begin_offset = i\n",
        "        prev_tag = tag\n",
        "        prev_type = type_\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def end_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    chunk_end = False\n",
        "\n",
        "    if prev_tag == 'E': chunk_end = True\n",
        "    if prev_tag == 'S': chunk_end = True\n",
        "\n",
        "    if prev_tag == 'B' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'O': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'O': chunk_end = True\n",
        "\n",
        "    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n",
        "        chunk_end = True\n",
        "\n",
        "    return chunk_end\n",
        "\n",
        "\n",
        "def start_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    chunk_start = False\n",
        "\n",
        "    if tag == 'B': chunk_start = True\n",
        "    if tag == 'S': chunk_start = True\n",
        "\n",
        "    if prev_tag == 'E' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'E' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'I': chunk_start = True\n",
        "\n",
        "    if tag != 'O' and tag != '.' and prev_type != type_:\n",
        "        chunk_start = True\n",
        "\n",
        "    return chunk_start\n",
        "\n",
        "\n",
        "def f1_score(y_true, y_pred, average='micro', digits=2, suffix=False):\n",
        "    true_entities = set(get_entities(y_true, suffix))\n",
        "    pred_entities = set(get_entities(y_pred, suffix))\n",
        "\n",
        "    nb_correct = len(true_entities & pred_entities)\n",
        "    nb_pred = len(pred_entities)\n",
        "    nb_true = len(true_entities)\n",
        "\n",
        "    p = 100 * nb_correct / nb_pred if nb_pred > 0 else 0\n",
        "    r = 100 * nb_correct / nb_true if nb_true > 0 else 0\n",
        "    score = 2 * p * r / (p + r) if p + r > 0 else 0\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    if any(isinstance(s, list) for s in y_true):\n",
        "        y_true = [item for sublist in y_true for item in sublist]\n",
        "        y_pred = [item for sublist in y_pred for item in sublist]\n",
        "\n",
        "    nb_correct = sum(y_t==y_p for y_t, y_p in zip(y_true, y_pred))\n",
        "    nb_true = len(y_true)\n",
        "\n",
        "    score = nb_correct / nb_true\n",
        "\n",
        "    return score\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bFCJ-6ttlgR",
        "outputId": "6118ee8d-4d94-45f9-e8da-cd1791279d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "# ! pip install pytorch-crf\n",
        "from torchcrf import CRF\n",
        "\n",
        "model_crf = CRF(len(args.tag2idx))\n",
        "\n",
        "if args.store_dir is not None:\n",
        "    model = BertForSequenceTagging.from_pretrained(model_params_dir)\n",
        "\n",
        "best_val_f1 = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(1, args.max_epoch_num +1):\n",
        "    epoch_start = time.time()\n",
        "    \n",
        "    print('\\n*****',' Train Epoch {0}/{1} '.format(epoch, args.max_epoch_num), '*****')\n",
        "    \n",
        "    train_steps = args.train_size // args.batch_size\n",
        "    val_steps = args.val_size // args.batch_size\n",
        "    \n",
        "    train_data_iterator = data_loader.data_iterator(train, shuffle=True)\n",
        "    val_data_iterator = data_loader.data_iterator(val, shuffle=True)\n",
        "    \n",
        "    # Train step\n",
        "    model.train()\n",
        "    epoch_loss, epoch_avg_loss = 0.0, 0.0\n",
        "\n",
        "    for batch in range(1, train_steps+1):\n",
        "        batch_data, batch_token_starts, batch_tags = next(train_data_iterator)\n",
        "        batch_masks = batch_data.gt(0)\n",
        "        loss = model(batch_data[:,1:], attn_masks=batch_masks[:,1:], labels=batch_tags)\n",
        "                    \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=args.clip_grad)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_avg_loss = epoch_loss / (batch+1)\n",
        "        \n",
        "        if batch % 50 == 0:\n",
        "            print('| Train_epoch: {0} | Train_batch: {1}/{2} | Train_batch_loss: {3:4f} |'.format(epoch, batch, train_steps, epoch_avg_loss))\n",
        "    \n",
        "    # Val step\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    true_tags, pred_tags = [], []\n",
        "    \n",
        "    for _ in range(val_steps):\n",
        "        batch_data, batch_token_starts, batch_tags = next(val_data_iterator)\n",
        "        batch_masks = batch_data.gt(0)\n",
        "        \n",
        "        loss = model(batch_data[:,1:], attn_masks=batch_masks[:,1:], labels=batch_tags)\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "        batch_outs = model(batch_data[:,1:], attn_masks=batch_masks[:,1:])\n",
        "        batch_tags = batch_tags.to('cpu').numpy()\n",
        "        \n",
        "#         print(len(batch_outs), len(batch_outs[1]), len(batch_outs[2]))\n",
        "#         print(batch_tags.shape)\n",
        "        \n",
        "        pred_tags.extend([[args.idx2tag.get(idx) for idx in indices] for indices in batch_outs])\n",
        "        for indices in batch_tags:\n",
        "            tmp = []\n",
        "            for idx in indices:\n",
        "                if idx != -1:\n",
        "                    tmp.append(args.idx2tag.get(idx))\n",
        "                else:\n",
        "                    pass\n",
        "            true_tags.append(tmp)\n",
        "    \n",
        "    assert len(pred_tags) == len(true_tags)\n",
        "\n",
        "    f1 = f1_score(true_tags, pred_tags)\n",
        "    loss = val_loss / val_steps\n",
        "    acc = accuracy_score(true_tags, pred_tags)\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_mins, epoch_secs = int(epoch_time/60), int(epoch_time%60)\n",
        "    \n",
        "    print('| Train_epoch: {0} | Train_loss: {2:4f} | Train&Val_time: {3}m {4}s |'.format(epoch, args.max_epoch_num, epoch_avg_loss, epoch_mins, epoch_secs))\n",
        "    print('                 | Valid_loss: {0:4f} | Valid_f1: {1:4f} | Valid_Acc: {2:2f}% |'.format(loss, f1, 100*acc))\n",
        "\n",
        "    if f1 - best_val_f1 >= 0.1:\n",
        "        best_val_f1 = f1\n",
        "        \n",
        "        model_to_save = model.module if hasattr(model, 'module') else model\n",
        "        model_path = model_params_dir + '/pytorch_model.bin'\n",
        "        config_path = model_params_dir + '/config.json'\n",
        "        \n",
        "        torch.save(model_to_save.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        model_to_save.config.to_json_file(config_path)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*****  Train Epoch 1/5  *****\n",
            "| Train_epoch: 1 | Train_batch: 50/1335 | Train_batch_loss: 48.952266 |\n",
            "| Train_epoch: 1 | Train_batch: 100/1335 | Train_batch_loss: 31.488093 |\n",
            "| Train_epoch: 1 | Train_batch: 150/1335 | Train_batch_loss: 23.571943 |\n",
            "| Train_epoch: 1 | Train_batch: 200/1335 | Train_batch_loss: 18.847176 |\n",
            "| Train_epoch: 1 | Train_batch: 250/1335 | Train_batch_loss: 15.797430 |\n",
            "| Train_epoch: 1 | Train_batch: 300/1335 | Train_batch_loss: 13.721520 |\n",
            "| Train_epoch: 1 | Train_batch: 350/1335 | Train_batch_loss: 12.182213 |\n",
            "| Train_epoch: 1 | Train_batch: 400/1335 | Train_batch_loss: 11.020385 |\n",
            "| Train_epoch: 1 | Train_batch: 450/1335 | Train_batch_loss: 10.060620 |\n",
            "| Train_epoch: 1 | Train_batch: 500/1335 | Train_batch_loss: 9.282598 |\n",
            "| Train_epoch: 1 | Train_batch: 550/1335 | Train_batch_loss: 8.641522 |\n",
            "| Train_epoch: 1 | Train_batch: 600/1335 | Train_batch_loss: 8.085905 |\n",
            "| Train_epoch: 1 | Train_batch: 650/1335 | Train_batch_loss: 7.649074 |\n",
            "| Train_epoch: 1 | Train_batch: 700/1335 | Train_batch_loss: 7.233496 |\n",
            "| Train_epoch: 1 | Train_batch: 750/1335 | Train_batch_loss: 6.871703 |\n",
            "| Train_epoch: 1 | Train_batch: 800/1335 | Train_batch_loss: 6.554121 |\n",
            "| Train_epoch: 1 | Train_batch: 850/1335 | Train_batch_loss: 6.263937 |\n",
            "| Train_epoch: 1 | Train_batch: 900/1335 | Train_batch_loss: 6.023023 |\n",
            "| Train_epoch: 1 | Train_batch: 950/1335 | Train_batch_loss: 5.798558 |\n",
            "| Train_epoch: 1 | Train_batch: 1000/1335 | Train_batch_loss: 5.592528 |\n",
            "| Train_epoch: 1 | Train_batch: 1050/1335 | Train_batch_loss: 5.404917 |\n",
            "| Train_epoch: 1 | Train_batch: 1100/1335 | Train_batch_loss: 5.232504 |\n",
            "| Train_epoch: 1 | Train_batch: 1150/1335 | Train_batch_loss: 5.071993 |\n",
            "| Train_epoch: 1 | Train_batch: 1200/1335 | Train_batch_loss: 4.929236 |\n",
            "| Train_epoch: 1 | Train_batch: 1250/1335 | Train_batch_loss: 4.788867 |\n",
            "| Train_epoch: 1 | Train_batch: 1300/1335 | Train_batch_loss: 4.660422 |\n",
            "| Train_epoch: 1 | Train_loss: 4.580957 | Train&Val_time: 7m 37s |\n",
            "                 | Valid_loss: 1.425186 | Valid_f1: 90.933842 | Valid_Acc: 99.101785% |\n",
            "\n",
            "*****  Train Epoch 2/5  *****\n",
            "| Train_epoch: 2 | Train_batch: 50/1335 | Train_batch_loss: 1.452245 |\n",
            "| Train_epoch: 2 | Train_batch: 100/1335 | Train_batch_loss: 1.428667 |\n",
            "| Train_epoch: 2 | Train_batch: 150/1335 | Train_batch_loss: 1.440853 |\n",
            "| Train_epoch: 2 | Train_batch: 200/1335 | Train_batch_loss: 1.426370 |\n",
            "| Train_epoch: 2 | Train_batch: 250/1335 | Train_batch_loss: 1.391759 |\n",
            "| Train_epoch: 2 | Train_batch: 300/1335 | Train_batch_loss: 1.395199 |\n",
            "| Train_epoch: 2 | Train_batch: 350/1335 | Train_batch_loss: 1.373974 |\n",
            "| Train_epoch: 2 | Train_batch: 400/1335 | Train_batch_loss: 1.336794 |\n",
            "| Train_epoch: 2 | Train_batch: 450/1335 | Train_batch_loss: 1.314941 |\n",
            "| Train_epoch: 2 | Train_batch: 500/1335 | Train_batch_loss: 1.293204 |\n",
            "| Train_epoch: 2 | Train_batch: 550/1335 | Train_batch_loss: 1.278653 |\n",
            "| Train_epoch: 2 | Train_batch: 600/1335 | Train_batch_loss: 1.251593 |\n",
            "| Train_epoch: 2 | Train_batch: 650/1335 | Train_batch_loss: 1.238749 |\n",
            "| Train_epoch: 2 | Train_batch: 700/1335 | Train_batch_loss: 1.214045 |\n",
            "| Train_epoch: 2 | Train_batch: 750/1335 | Train_batch_loss: 1.186242 |\n",
            "| Train_epoch: 2 | Train_batch: 800/1335 | Train_batch_loss: 1.170351 |\n",
            "| Train_epoch: 2 | Train_batch: 850/1335 | Train_batch_loss: 1.147325 |\n",
            "| Train_epoch: 2 | Train_batch: 900/1335 | Train_batch_loss: 1.139106 |\n",
            "| Train_epoch: 2 | Train_batch: 950/1335 | Train_batch_loss: 1.116393 |\n",
            "| Train_epoch: 2 | Train_batch: 1000/1335 | Train_batch_loss: 1.102834 |\n",
            "| Train_epoch: 2 | Train_batch: 1050/1335 | Train_batch_loss: 1.083469 |\n",
            "| Train_epoch: 2 | Train_batch: 1100/1335 | Train_batch_loss: 1.067085 |\n",
            "| Train_epoch: 2 | Train_batch: 1150/1335 | Train_batch_loss: 1.051392 |\n",
            "| Train_epoch: 2 | Train_batch: 1200/1335 | Train_batch_loss: 1.036926 |\n",
            "| Train_epoch: 2 | Train_batch: 1250/1335 | Train_batch_loss: 1.019760 |\n",
            "| Train_epoch: 2 | Train_batch: 1300/1335 | Train_batch_loss: 1.003762 |\n",
            "| Train_epoch: 2 | Train_loss: 0.995058 | Train&Val_time: 7m 45s |\n",
            "                 | Valid_loss: 1.216517 | Valid_f1: 93.990121 | Valid_Acc: 99.343722% |\n",
            "\n",
            "*****  Train Epoch 3/5  *****\n",
            "| Train_epoch: 3 | Train_batch: 50/1335 | Train_batch_loss: 0.723789 |\n",
            "| Train_epoch: 3 | Train_batch: 100/1335 | Train_batch_loss: 0.634304 |\n",
            "| Train_epoch: 3 | Train_batch: 150/1335 | Train_batch_loss: 0.653257 |\n",
            "| Train_epoch: 3 | Train_batch: 200/1335 | Train_batch_loss: 0.610892 |\n",
            "| Train_epoch: 3 | Train_batch: 250/1335 | Train_batch_loss: 0.609858 |\n",
            "| Train_epoch: 3 | Train_batch: 300/1335 | Train_batch_loss: 0.608908 |\n",
            "| Train_epoch: 3 | Train_batch: 350/1335 | Train_batch_loss: 0.616229 |\n",
            "| Train_epoch: 3 | Train_batch: 400/1335 | Train_batch_loss: 0.609794 |\n",
            "| Train_epoch: 3 | Train_batch: 450/1335 | Train_batch_loss: 0.610464 |\n",
            "| Train_epoch: 3 | Train_batch: 500/1335 | Train_batch_loss: 0.609141 |\n",
            "| Train_epoch: 3 | Train_batch: 550/1335 | Train_batch_loss: 0.604890 |\n",
            "| Train_epoch: 3 | Train_batch: 600/1335 | Train_batch_loss: 0.592726 |\n",
            "| Train_epoch: 3 | Train_batch: 650/1335 | Train_batch_loss: 0.586811 |\n",
            "| Train_epoch: 3 | Train_batch: 700/1335 | Train_batch_loss: 0.573611 |\n",
            "| Train_epoch: 3 | Train_batch: 750/1335 | Train_batch_loss: 0.558073 |\n",
            "| Train_epoch: 3 | Train_batch: 800/1335 | Train_batch_loss: 0.544652 |\n",
            "| Train_epoch: 3 | Train_batch: 850/1335 | Train_batch_loss: 0.532335 |\n",
            "| Train_epoch: 3 | Train_batch: 900/1335 | Train_batch_loss: 0.539871 |\n",
            "| Train_epoch: 3 | Train_batch: 950/1335 | Train_batch_loss: 0.530631 |\n",
            "| Train_epoch: 3 | Train_batch: 1000/1335 | Train_batch_loss: 0.529690 |\n",
            "| Train_epoch: 3 | Train_batch: 1050/1335 | Train_batch_loss: 0.522411 |\n",
            "| Train_epoch: 3 | Train_batch: 1100/1335 | Train_batch_loss: 0.514280 |\n",
            "| Train_epoch: 3 | Train_batch: 1150/1335 | Train_batch_loss: 0.506884 |\n",
            "| Train_epoch: 3 | Train_batch: 1200/1335 | Train_batch_loss: 0.503956 |\n",
            "| Train_epoch: 3 | Train_batch: 1250/1335 | Train_batch_loss: 0.496010 |\n",
            "| Train_epoch: 3 | Train_batch: 1300/1335 | Train_batch_loss: 0.488267 |\n",
            "| Train_epoch: 3 | Train_loss: 0.485380 | Train&Val_time: 7m 44s |\n",
            "                 | Valid_loss: 1.445572 | Valid_f1: 95.303300 | Valid_Acc: 99.414208% |\n",
            "\n",
            "*****  Train Epoch 4/5  *****\n",
            "| Train_epoch: 4 | Train_batch: 50/1335 | Train_batch_loss: 0.290438 |\n",
            "| Train_epoch: 4 | Train_batch: 100/1335 | Train_batch_loss: 0.280937 |\n",
            "| Train_epoch: 4 | Train_batch: 150/1335 | Train_batch_loss: 0.316689 |\n",
            "| Train_epoch: 4 | Train_batch: 200/1335 | Train_batch_loss: 0.298416 |\n",
            "| Train_epoch: 4 | Train_batch: 250/1335 | Train_batch_loss: 0.324525 |\n",
            "| Train_epoch: 4 | Train_batch: 300/1335 | Train_batch_loss: 0.327293 |\n",
            "| Train_epoch: 4 | Train_batch: 350/1335 | Train_batch_loss: 0.329070 |\n",
            "| Train_epoch: 4 | Train_batch: 400/1335 | Train_batch_loss: 0.325521 |\n",
            "| Train_epoch: 4 | Train_batch: 450/1335 | Train_batch_loss: 0.326913 |\n",
            "| Train_epoch: 4 | Train_batch: 500/1335 | Train_batch_loss: 0.318713 |\n",
            "| Train_epoch: 4 | Train_batch: 550/1335 | Train_batch_loss: 0.309175 |\n",
            "| Train_epoch: 4 | Train_batch: 600/1335 | Train_batch_loss: 0.303884 |\n",
            "| Train_epoch: 4 | Train_batch: 650/1335 | Train_batch_loss: 0.302560 |\n",
            "| Train_epoch: 4 | Train_batch: 700/1335 | Train_batch_loss: 0.300984 |\n",
            "| Train_epoch: 4 | Train_batch: 750/1335 | Train_batch_loss: 0.294450 |\n",
            "| Train_epoch: 4 | Train_batch: 800/1335 | Train_batch_loss: 0.288554 |\n",
            "| Train_epoch: 4 | Train_batch: 850/1335 | Train_batch_loss: 0.280566 |\n",
            "| Train_epoch: 4 | Train_batch: 900/1335 | Train_batch_loss: 0.278013 |\n",
            "| Train_epoch: 4 | Train_batch: 950/1335 | Train_batch_loss: 0.274659 |\n",
            "| Train_epoch: 4 | Train_batch: 1000/1335 | Train_batch_loss: 0.273687 |\n",
            "| Train_epoch: 4 | Train_batch: 1050/1335 | Train_batch_loss: 0.271335 |\n",
            "| Train_epoch: 4 | Train_batch: 1100/1335 | Train_batch_loss: 0.267097 |\n",
            "| Train_epoch: 4 | Train_batch: 1150/1335 | Train_batch_loss: 0.264132 |\n",
            "| Train_epoch: 4 | Train_batch: 1200/1335 | Train_batch_loss: 0.262249 |\n",
            "| Train_epoch: 4 | Train_batch: 1250/1335 | Train_batch_loss: 0.259874 |\n",
            "| Train_epoch: 4 | Train_batch: 1300/1335 | Train_batch_loss: 0.255777 |\n",
            "| Train_epoch: 4 | Train_loss: 0.251802 | Train&Val_time: 7m 44s |\n",
            "                 | Valid_loss: 1.538945 | Valid_f1: 95.754911 | Valid_Acc: 99.437068% |\n",
            "\n",
            "*****  Train Epoch 5/5  *****\n",
            "| Train_epoch: 5 | Train_batch: 50/1335 | Train_batch_loss: 0.222381 |\n",
            "| Train_epoch: 5 | Train_batch: 100/1335 | Train_batch_loss: 0.202667 |\n",
            "| Train_epoch: 5 | Train_batch: 150/1335 | Train_batch_loss: 0.197371 |\n",
            "| Train_epoch: 5 | Train_batch: 200/1335 | Train_batch_loss: 0.177245 |\n",
            "| Train_epoch: 5 | Train_batch: 250/1335 | Train_batch_loss: 0.185790 |\n",
            "| Train_epoch: 5 | Train_batch: 300/1335 | Train_batch_loss: 0.187088 |\n",
            "| Train_epoch: 5 | Train_batch: 350/1335 | Train_batch_loss: 0.180200 |\n",
            "| Train_epoch: 5 | Train_batch: 400/1335 | Train_batch_loss: 0.168055 |\n",
            "| Train_epoch: 5 | Train_batch: 450/1335 | Train_batch_loss: 0.167833 |\n",
            "| Train_epoch: 5 | Train_batch: 500/1335 | Train_batch_loss: 0.169372 |\n",
            "| Train_epoch: 5 | Train_batch: 550/1335 | Train_batch_loss: 0.166542 |\n",
            "| Train_epoch: 5 | Train_batch: 600/1335 | Train_batch_loss: 0.164385 |\n",
            "| Train_epoch: 5 | Train_batch: 650/1335 | Train_batch_loss: 0.163794 |\n",
            "| Train_epoch: 5 | Train_batch: 700/1335 | Train_batch_loss: 0.161818 |\n",
            "| Train_epoch: 5 | Train_batch: 750/1335 | Train_batch_loss: 0.157205 |\n",
            "| Train_epoch: 5 | Train_batch: 800/1335 | Train_batch_loss: 0.151534 |\n",
            "| Train_epoch: 5 | Train_batch: 850/1335 | Train_batch_loss: 0.148064 |\n",
            "| Train_epoch: 5 | Train_batch: 900/1335 | Train_batch_loss: 0.148519 |\n",
            "| Train_epoch: 5 | Train_batch: 950/1335 | Train_batch_loss: 0.146366 |\n",
            "| Train_epoch: 5 | Train_batch: 1000/1335 | Train_batch_loss: 0.147243 |\n",
            "| Train_epoch: 5 | Train_batch: 1050/1335 | Train_batch_loss: 0.145047 |\n",
            "| Train_epoch: 5 | Train_batch: 1100/1335 | Train_batch_loss: 0.142756 |\n",
            "| Train_epoch: 5 | Train_batch: 1150/1335 | Train_batch_loss: 0.141215 |\n",
            "| Train_epoch: 5 | Train_batch: 1200/1335 | Train_batch_loss: 0.139207 |\n",
            "| Train_epoch: 5 | Train_batch: 1250/1335 | Train_batch_loss: 0.136333 |\n",
            "| Train_epoch: 5 | Train_batch: 1300/1335 | Train_batch_loss: 0.134730 |\n",
            "| Train_epoch: 5 | Train_loss: 0.133642 | Train&Val_time: 7m 42s |\n",
            "                 | Valid_loss: 1.517609 | Valid_f1: 96.085703 | Valid_Acc: 99.492313% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDleywUntlgV"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}